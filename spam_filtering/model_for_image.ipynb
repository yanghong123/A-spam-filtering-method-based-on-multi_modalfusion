{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (2786, 128, 128, 3)\n",
      "Shape of label tensor: (2786, 2)\n",
      "x_train.shape (2786, 128, 128, 3)\n",
      "y_train.shape (2786, 2)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:UTF-8 -*-\n",
    "#process image\n",
    "import keras, cv2,os\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "def read_image(imageName):\n",
    "    img=cv2.imread(imageName,cv2.IMREAD_COLOR)\n",
    "    #method1\n",
    "    if img is None:\n",
    "            return None;\n",
    "    else:\n",
    "        img = cv2.resize(img,dsize=(128,128),interpolation=cv2.INTER_LINEAR)\n",
    "        img = img.astype(\"float32\")\n",
    "        img *= (1./255)\n",
    "        b,g,r=cv2.split(img)\n",
    "        img2=cv2.merge([r,g,b])\n",
    "        return img2\n",
    "        \n",
    "def img_processing(path,x,y):\n",
    "    directory =os.listdir(path)\n",
    "    for textPath in directory:\n",
    "        for fn in os.listdir(os.path.join(r\"\",path+ textPath)):\n",
    "#             if fn.endswith('.png') or fn.endswith('.jpg'):\n",
    "            fd = os.path.join(path, textPath, fn)\n",
    "            img_arr=read_image(fd)\n",
    "            if(img_arr is not None):\n",
    "                x.append(img_arr)\n",
    "                if(textPath==\"ham\"):\n",
    "                    y.append(0)\n",
    "                else:\n",
    "                    y.append(1)\n",
    "    return x,y  \n",
    "x,y=[],[]\n",
    "# get image email dataset path\n",
    "path1=\"/home/aqts/yangHong/first-spam-experiment/data/image_email_dataset/\"\n",
    "\n",
    "x,y=img_processing(path1,x,y)\n",
    "# VALIDATION_SPLIT=0.8\n",
    "\n",
    "\n",
    "data = np.array(x)\n",
    "\n",
    "labels = to_categorical(np.asarray(y))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "# num_validation_samples = int( VALIDATION_SPLIT* data.shape[0])\n",
    "# val_num=num_validation_samples+int(0.2* data.shape[0])\n",
    "x_train = data[:]\n",
    "y_train = labels[:]\n",
    "# x_valid = data[num_validation_samples:val_num]\n",
    "# y_valid = labels[num_validation_samples:val_num]\n",
    "# x_test = data[num_validation_samples:]\n",
    "# y_test = labels[num_validation_samples:]\n",
    "\n",
    "print('x_train.shape',x_train.shape)\n",
    "print('y_train.shape',y_train.shape)\n",
    "# print('x_valid.shape',x_valid.shape)\n",
    "# print('y_valid.shape',y_valid.shape)\n",
    "# print('x_test.shape',x_test.shape)\n",
    "# print('y_test.shape',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aqts/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/aqts/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/32\n",
      "2228/2228 [==============================] - 93s 42ms/step - loss: 0.4263 - acc: 0.8012\n",
      "Epoch 2/32\n",
      "2228/2228 [==============================] - 92s 41ms/step - loss: 0.2611 - acc: 0.8986\n",
      "Epoch 3/32\n",
      "2228/2228 [==============================] - 92s 41ms/step - loss: 0.1943 - acc: 0.9237\n",
      "Epoch 4/32\n",
      "2228/2228 [==============================] - 92s 41ms/step - loss: 0.1326 - acc: 0.9641\n",
      "Epoch 5/32\n",
      "2228/2228 [==============================] - 91s 41ms/step - loss: 0.0975 - acc: 0.9744\n",
      "Epoch 6/32\n",
      "2228/2228 [==============================] - 92s 41ms/step - loss: 0.0620 - acc: 0.9852\n",
      "Epoch 7/32\n",
      "2228/2228 [==============================] - 91s 41ms/step - loss: 0.0387 - acc: 0.9933\n",
      "Epoch 8/32\n",
      "2228/2228 [==============================] - 91s 41ms/step - loss: 0.0504 - acc: 0.9852\n",
      "Epoch 9/32\n",
      "2228/2228 [==============================] - 91s 41ms/step - loss: 0.0678 - acc: 0.9803\n",
      "Epoch 10/32\n",
      "2228/2228 [==============================] - 91s 41ms/step - loss: 0.0443 - acc: 0.9901\n",
      "Epoch 11/32\n",
      "2228/2228 [==============================] - 91s 41ms/step - loss: 0.0239 - acc: 0.9960\n",
      "Epoch 12/32\n",
      "2228/2228 [==============================] - 92s 41ms/step - loss: 0.0173 - acc: 0.9978\n",
      "Epoch 13/32\n",
      "2228/2228 [==============================] - 107s 48ms/step - loss: 0.0245 - acc: 0.9946\n",
      "Epoch 14/32\n",
      "2228/2228 [==============================] - 129s 58ms/step - loss: 0.0192 - acc: 0.9946\n",
      "Epoch 15/32\n",
      "2228/2228 [==============================] - 102s 46ms/step - loss: 0.0272 - acc: 0.9946\n",
      "Epoch 16/32\n",
      "2228/2228 [==============================] - 121s 54ms/step - loss: 0.0143 - acc: 0.9973\n",
      "Epoch 17/32\n",
      "2228/2228 [==============================] - 129s 58ms/step - loss: 0.0432 - acc: 0.9838\n",
      "Epoch 18/32\n",
      "2228/2228 [==============================] - 129s 58ms/step - loss: 0.0131 - acc: 0.9982\n",
      "Epoch 19/32\n",
      "2228/2228 [==============================] - 128s 58ms/step - loss: 0.0159 - acc: 0.9969\n",
      "Epoch 20/32\n",
      "2228/2228 [==============================] - 112s 50ms/step - loss: 0.0123 - acc: 0.9969\n",
      "Epoch 21/32\n",
      "2228/2228 [==============================] - 91s 41ms/step - loss: 0.0191 - acc: 0.9960\n",
      "Epoch 22/32\n",
      "2228/2228 [==============================] - 91s 41ms/step - loss: 0.0106 - acc: 0.9982\n",
      "Epoch 23/32\n",
      "2228/2228 [==============================] - 91s 41ms/step - loss: 0.0079 - acc: 0.9982\n",
      "Epoch 24/32\n",
      "2228/2228 [==============================] - 134s 60ms/step - loss: 0.0084 - acc: 0.9973\n",
      "Epoch 25/32\n",
      "2228/2228 [==============================] - 146s 66ms/step - loss: 0.0091 - acc: 0.9982\n",
      "Epoch 26/32\n",
      "2228/2228 [==============================] - 147s 66ms/step - loss: 0.0069 - acc: 0.9973\n",
      "Epoch 27/32\n",
      "2228/2228 [==============================] - 153s 69ms/step - loss: 0.0070 - acc: 0.9978\n",
      "Epoch 28/32\n",
      "2228/2228 [==============================] - 153s 69ms/step - loss: 0.0065 - acc: 0.9982\n",
      "Epoch 29/32\n",
      "2228/2228 [==============================] - 153s 69ms/step - loss: 0.0071 - acc: 0.9982\n",
      "Epoch 30/32\n",
      "2228/2228 [==============================] - 154s 69ms/step - loss: 0.0056 - acc: 0.9991\n",
      "Epoch 31/32\n",
      "2228/2228 [==============================] - 152s 68ms/step - loss: 0.0062 - acc: 0.9982\n",
      "Epoch 32/32\n",
      "2228/2228 [==============================] - 152s 68ms/step - loss: 0.0047 - acc: 0.9991\n",
      "---------------------------Precision-----------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90       270\n",
      "           1       0.98      0.81      0.89       288\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       558\n",
      "   macro avg       0.91      0.90      0.90       558\n",
      "weighted avg       0.91      0.90      0.90       558\n",
      " samples avg       0.90      0.90      0.90       558\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "2229/2229 [==============================] - 154s 69ms/step - loss: 0.3915 - acc: 0.8277\n",
      "Epoch 2/32\n",
      "2229/2229 [==============================] - 152s 68ms/step - loss: 0.2623 - acc: 0.8919\n",
      "Epoch 3/32\n",
      "2229/2229 [==============================] - 152s 68ms/step - loss: 0.1746 - acc: 0.9390\n",
      "Epoch 4/32\n",
      "2229/2229 [==============================] - 153s 69ms/step - loss: 0.1326 - acc: 0.9592\n",
      "Epoch 5/32\n",
      "2229/2229 [==============================] - 151s 68ms/step - loss: 0.0909 - acc: 0.9753\n",
      "Epoch 6/32\n",
      "2229/2229 [==============================] - 132s 59ms/step - loss: 0.0624 - acc: 0.9856\n",
      "Epoch 7/32\n",
      "2229/2229 [==============================] - 139s 62ms/step - loss: 0.0583 - acc: 0.9838\n",
      "Epoch 8/32\n",
      "2229/2229 [==============================] - 151s 68ms/step - loss: 0.0353 - acc: 0.9919\n",
      "Epoch 9/32\n",
      "2229/2229 [==============================] - 152s 68ms/step - loss: 0.0323 - acc: 0.9937\n",
      "Epoch 10/32\n",
      "2229/2229 [==============================] - 153s 69ms/step - loss: 0.0276 - acc: 0.9955\n",
      "Epoch 11/32\n",
      "2229/2229 [==============================] - 153s 69ms/step - loss: 0.0462 - acc: 0.9879\n",
      "Epoch 12/32\n",
      "2229/2229 [==============================] - 152s 68ms/step - loss: 0.0254 - acc: 0.9942\n",
      "Epoch 13/32\n",
      "2229/2229 [==============================] - 152s 68ms/step - loss: 0.0223 - acc: 0.9955\n",
      "Epoch 14/32\n",
      "2229/2229 [==============================] - 153s 68ms/step - loss: 0.0162 - acc: 0.9973\n",
      "Epoch 15/32\n",
      "2229/2229 [==============================] - 155s 70ms/step - loss: 0.0137 - acc: 0.9969\n",
      "Epoch 16/32\n",
      "2229/2229 [==============================] - 152s 68ms/step - loss: 0.0184 - acc: 0.9955\n",
      "Epoch 17/32\n",
      "2229/2229 [==============================] - 152s 68ms/step - loss: 0.0131 - acc: 0.9964\n",
      "Epoch 18/32\n",
      "2229/2229 [==============================] - 203s 91ms/step - loss: 0.0123 - acc: 0.9973\n",
      "Epoch 19/32\n",
      "2229/2229 [==============================] - 219s 98ms/step - loss: 0.0124 - acc: 0.9978\n",
      "Epoch 20/32\n",
      "2229/2229 [==============================] - 151s 68ms/step - loss: 0.0162 - acc: 0.9951\n",
      "Epoch 21/32\n",
      "2229/2229 [==============================] - 205s 92ms/step - loss: 0.0149 - acc: 0.9973\n",
      "Epoch 22/32\n",
      "2229/2229 [==============================] - 219s 98ms/step - loss: 0.0095 - acc: 0.9973\n",
      "Epoch 23/32\n",
      "2229/2229 [==============================] - 217s 97ms/step - loss: 0.0207 - acc: 0.9942\n",
      "Epoch 24/32\n",
      "2229/2229 [==============================] - 220s 99ms/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 25/32\n",
      "2229/2229 [==============================] - 220s 99ms/step - loss: 0.0149 - acc: 0.9951\n",
      "Epoch 26/32\n",
      "2229/2229 [==============================] - 219s 98ms/step - loss: 0.0089 - acc: 0.9982\n",
      "Epoch 27/32\n",
      "2229/2229 [==============================] - 219s 98ms/step - loss: 0.0067 - acc: 0.9991\n",
      "Epoch 28/32\n",
      "2229/2229 [==============================] - 220s 99ms/step - loss: 0.0099 - acc: 0.9973\n",
      "Epoch 29/32\n",
      "2229/2229 [==============================] - 218s 98ms/step - loss: 0.0086 - acc: 0.9973\n",
      "Epoch 30/32\n",
      "2229/2229 [==============================] - 221s 99ms/step - loss: 0.0079 - acc: 0.9982\n",
      "Epoch 31/32\n",
      "2229/2229 [==============================] - 221s 99ms/step - loss: 0.0081 - acc: 0.9973\n",
      "Epoch 32/32\n",
      "2229/2229 [==============================] - 220s 99ms/step - loss: 0.0072 - acc: 0.9978\n",
      "---------------------------Precision-----------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       293\n",
      "           1       0.93      0.83      0.88       264\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       557\n",
      "   macro avg       0.90      0.89      0.89       557\n",
      "weighted avg       0.90      0.89      0.89       557\n",
      " samples avg       0.89      0.89      0.89       557\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "2229/2229 [==============================] - 222s 99ms/step - loss: 0.4140 - acc: 0.8080\n",
      "Epoch 2/32\n",
      "2229/2229 [==============================] - 191s 86ms/step - loss: 0.2669 - acc: 0.8914\n",
      "Epoch 3/32\n",
      "2229/2229 [==============================] - 111s 50ms/step - loss: 0.1837 - acc: 0.9358\n",
      "Epoch 4/32\n",
      "2229/2229 [==============================] - 110s 49ms/step - loss: 0.1199 - acc: 0.9668\n",
      "Epoch 5/32\n",
      "2229/2229 [==============================] - 116s 52ms/step - loss: 0.0884 - acc: 0.9771\n",
      "Epoch 6/32\n",
      "2229/2229 [==============================] - 102s 46ms/step - loss: 0.0761 - acc: 0.9771\n",
      "Epoch 7/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0545 - acc: 0.9838\n",
      "Epoch 8/32\n",
      "2229/2229 [==============================] - 89s 40ms/step - loss: 0.0410 - acc: 0.9924\n",
      "Epoch 9/32\n",
      "2229/2229 [==============================] - 104s 47ms/step - loss: 0.0411 - acc: 0.9870\n",
      "Epoch 10/32\n",
      "2229/2229 [==============================] - 96s 43ms/step - loss: 0.0230 - acc: 0.9960\n",
      "Epoch 11/32\n",
      "2229/2229 [==============================] - 93s 42ms/step - loss: 0.0204 - acc: 0.9960\n",
      "Epoch 12/32\n",
      "2229/2229 [==============================] - 93s 42ms/step - loss: 0.0191 - acc: 0.9964\n",
      "Epoch 13/32\n",
      "2229/2229 [==============================] - 90s 40ms/step - loss: 0.0212 - acc: 0.9960\n",
      "Epoch 14/32\n",
      "2229/2229 [==============================] - 90s 40ms/step - loss: 0.0550 - acc: 0.9897\n",
      "Epoch 15/32\n",
      "2229/2229 [==============================] - 90s 40ms/step - loss: 0.0182 - acc: 0.9964\n",
      "Epoch 16/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0145 - acc: 0.9973\n",
      "Epoch 17/32\n",
      "2229/2229 [==============================] - 141s 63ms/step - loss: 0.0092 - acc: 0.9991\n",
      "Epoch 18/32\n",
      "2229/2229 [==============================] - 89s 40ms/step - loss: 0.0112 - acc: 0.9973\n",
      "Epoch 19/32\n",
      "2229/2229 [==============================] - 90s 40ms/step - loss: 0.0113 - acc: 0.9982\n",
      "Epoch 20/32\n",
      "2229/2229 [==============================] - 90s 40ms/step - loss: 0.0119 - acc: 0.9973\n",
      "Epoch 21/32\n",
      "2229/2229 [==============================] - 92s 41ms/step - loss: 0.0093 - acc: 0.9973\n",
      "Epoch 22/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0109 - acc: 0.9969\n",
      "Epoch 23/32\n",
      "2229/2229 [==============================] - 98s 44ms/step - loss: 0.0109 - acc: 0.9960\n",
      "Epoch 24/32\n",
      "2229/2229 [==============================] - 99s 45ms/step - loss: 0.0074 - acc: 0.9987\n",
      "Epoch 25/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0060 - acc: 0.9982\n",
      "Epoch 26/32\n",
      "2229/2229 [==============================] - 94s 42ms/step - loss: 0.0076 - acc: 0.9982\n",
      "Epoch 27/32\n",
      "2229/2229 [==============================] - 93s 42ms/step - loss: 0.0054 - acc: 0.9987\n",
      "Epoch 28/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0051 - acc: 0.9982\n",
      "Epoch 29/32\n",
      "2229/2229 [==============================] - 92s 41ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 30/32\n",
      "2229/2229 [==============================] - 92s 41ms/step - loss: 0.0064 - acc: 0.9978\n",
      "Epoch 31/32\n",
      "2229/2229 [==============================] - 92s 41ms/step - loss: 0.0077 - acc: 0.9978\n",
      "Epoch 32/32\n",
      "2229/2229 [==============================] - 92s 41ms/step - loss: 0.0044 - acc: 0.9991\n",
      "---------------------------Precision-----------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       269\n",
      "           1       0.96      0.91      0.93       288\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       557\n",
      "   macro avg       0.93      0.93      0.93       557\n",
      "weighted avg       0.93      0.93      0.93       557\n",
      " samples avg       0.93      0.93      0.93       557\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "2229/2229 [==============================] - 92s 41ms/step - loss: 0.4164 - acc: 0.8017\n",
      "Epoch 2/32\n",
      "2229/2229 [==============================] - 90s 41ms/step - loss: 0.2700 - acc: 0.8901\n",
      "Epoch 3/32\n",
      "2229/2229 [==============================] - 92s 41ms/step - loss: 0.2003 - acc: 0.9233\n",
      "Epoch 4/32\n",
      "2229/2229 [==============================] - 90s 41ms/step - loss: 0.1456 - acc: 0.9515\n",
      "Epoch 5/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.1126 - acc: 0.9619\n",
      "Epoch 6/32\n",
      "2229/2229 [==============================] - 90s 41ms/step - loss: 0.0769 - acc: 0.9803\n",
      "Epoch 7/32\n",
      "2229/2229 [==============================] - 90s 40ms/step - loss: 0.0497 - acc: 0.9888\n",
      "Epoch 8/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0465 - acc: 0.9883\n",
      "Epoch 9/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0265 - acc: 0.9933\n",
      "Epoch 10/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0339 - acc: 0.9910\n",
      "Epoch 11/32\n",
      "2229/2229 [==============================] - 90s 41ms/step - loss: 0.0238 - acc: 0.9969\n",
      "Epoch 12/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0256 - acc: 0.9933\n",
      "Epoch 13/32\n",
      "2229/2229 [==============================] - 92s 41ms/step - loss: 0.0174 - acc: 0.9960\n",
      "Epoch 14/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0193 - acc: 0.9951\n",
      "Epoch 15/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0210 - acc: 0.9942\n",
      "Epoch 16/32\n",
      "2229/2229 [==============================] - 90s 41ms/step - loss: 0.0146 - acc: 0.9969\n",
      "Epoch 17/32\n",
      "2229/2229 [==============================] - 90s 41ms/step - loss: 0.0109 - acc: 0.9978\n",
      "Epoch 18/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0172 - acc: 0.9964\n",
      "Epoch 19/32\n",
      "2229/2229 [==============================] - 92s 41ms/step - loss: 0.0103 - acc: 0.9978\n",
      "Epoch 20/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0159 - acc: 0.9942\n",
      "Epoch 21/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0204 - acc: 0.9955\n",
      "Epoch 22/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0111 - acc: 0.9964\n",
      "Epoch 23/32\n",
      "2229/2229 [==============================] - 90s 41ms/step - loss: 0.0097 - acc: 0.9973\n",
      "Epoch 24/32\n",
      "2229/2229 [==============================] - 92s 41ms/step - loss: 0.0164 - acc: 0.9955\n",
      "Epoch 25/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0152 - acc: 0.9946\n",
      "Epoch 26/32\n",
      "2229/2229 [==============================] - 90s 41ms/step - loss: 0.0086 - acc: 0.9973\n",
      "Epoch 27/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0113 - acc: 0.9964\n",
      "Epoch 28/32\n",
      "2229/2229 [==============================] - 92s 41ms/step - loss: 0.0161 - acc: 0.9942\n",
      "Epoch 29/32\n",
      "2229/2229 [==============================] - 91s 41ms/step - loss: 0.0416 - acc: 0.9847\n",
      "Epoch 30/32\n",
      "2229/2229 [==============================] - 96s 43ms/step - loss: 0.0121 - acc: 0.9987\n",
      "Epoch 31/32\n",
      "2229/2229 [==============================] - 161s 72ms/step - loss: 0.0091 - acc: 0.9978\n",
      "Epoch 32/32\n",
      "2229/2229 [==============================] - 165s 74ms/step - loss: 0.0063 - acc: 0.9982\n",
      "---------------------------Precision-----------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       295\n",
      "           1       0.93      0.90      0.91       262\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       557\n",
      "   macro avg       0.92      0.92      0.92       557\n",
      "weighted avg       0.92      0.92      0.92       557\n",
      " samples avg       0.92      0.92      0.92       557\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "2229/2229 [==============================] - 167s 75ms/step - loss: 0.4148 - acc: 0.8035\n",
      "Epoch 2/32\n",
      "2229/2229 [==============================] - 161s 72ms/step - loss: 0.2713 - acc: 0.8905\n",
      "Epoch 3/32\n",
      "2229/2229 [==============================] - 161s 72ms/step - loss: 0.1887 - acc: 0.9323\n",
      "Epoch 4/32\n",
      "2229/2229 [==============================] - 156s 70ms/step - loss: 0.1357 - acc: 0.9592\n",
      "Epoch 5/32\n",
      "2229/2229 [==============================] - 160s 72ms/step - loss: 0.0901 - acc: 0.9762\n",
      "Epoch 6/32\n",
      "2229/2229 [==============================] - 158s 71ms/step - loss: 0.0719 - acc: 0.9794\n",
      "Epoch 7/32\n",
      "2229/2229 [==============================] - 160s 72ms/step - loss: 0.0487 - acc: 0.9874\n",
      "Epoch 8/32\n",
      "2229/2229 [==============================] - 182s 82ms/step - loss: 0.0445 - acc: 0.9856\n",
      "Epoch 9/32\n",
      "2229/2229 [==============================] - 228s 102ms/step - loss: 0.0411 - acc: 0.9861\n",
      "Epoch 10/32\n",
      "2229/2229 [==============================] - 181s 81ms/step - loss: 0.0365 - acc: 0.9928\n",
      "Epoch 11/32\n",
      "2229/2229 [==============================] - 145s 65ms/step - loss: 0.0287 - acc: 0.9924\n",
      "Epoch 12/32\n",
      "2229/2229 [==============================] - 148s 67ms/step - loss: 0.0229 - acc: 0.9951\n",
      "Epoch 13/32\n",
      "2229/2229 [==============================] - 146s 65ms/step - loss: 0.0187 - acc: 0.9960\n",
      "Epoch 14/32\n",
      "2229/2229 [==============================] - 143s 64ms/step - loss: 0.0113 - acc: 0.9978\n",
      "Epoch 15/32\n",
      "2229/2229 [==============================] - 144s 65ms/step - loss: 0.0178 - acc: 0.9955\n",
      "Epoch 16/32\n",
      "2229/2229 [==============================] - 145s 65ms/step - loss: 0.0130 - acc: 0.9969\n",
      "Epoch 17/32\n",
      "2229/2229 [==============================] - 148s 66ms/step - loss: 0.0198 - acc: 0.9942\n",
      "Epoch 18/32\n",
      "2229/2229 [==============================] - 147s 66ms/step - loss: 0.0148 - acc: 0.9955\n",
      "Epoch 19/32\n",
      "2229/2229 [==============================] - 146s 66ms/step - loss: 0.0093 - acc: 0.9982\n",
      "Epoch 20/32\n",
      "2229/2229 [==============================] - 148s 66ms/step - loss: 0.0145 - acc: 0.9969\n",
      "Epoch 21/32\n",
      "2229/2229 [==============================] - 147s 66ms/step - loss: 0.0126 - acc: 0.9955\n",
      "Epoch 22/32\n",
      "2229/2229 [==============================] - 148s 66ms/step - loss: 0.0169 - acc: 0.9951\n",
      "Epoch 23/32\n",
      "2229/2229 [==============================] - 146s 66ms/step - loss: 0.0129 - acc: 0.9973\n",
      "Epoch 24/32\n",
      "2229/2229 [==============================] - 142s 64ms/step - loss: 0.0073 - acc: 0.9987\n",
      "Epoch 25/32\n",
      "2229/2229 [==============================] - 147s 66ms/step - loss: 0.0070 - acc: 0.9987\n",
      "Epoch 26/32\n",
      "2229/2229 [==============================] - 148s 66ms/step - loss: 0.0063 - acc: 0.9987\n",
      "Epoch 27/32\n",
      "2229/2229 [==============================] - 148s 66ms/step - loss: 0.0089 - acc: 0.9969\n",
      "Epoch 28/32\n",
      "2229/2229 [==============================] - 145s 65ms/step - loss: 0.0074 - acc: 0.9978\n",
      "Epoch 29/32\n",
      "2229/2229 [==============================] - 147s 66ms/step - loss: 0.0049 - acc: 0.9991\n",
      "Epoch 30/32\n",
      "2229/2229 [==============================] - 146s 65ms/step - loss: 0.0080 - acc: 0.9969\n",
      "Epoch 31/32\n",
      "2229/2229 [==============================] - 148s 66ms/step - loss: 0.0085 - acc: 0.9982\n",
      "Epoch 32/32\n",
      "2229/2229 [==============================] - 147s 66ms/step - loss: 0.0081 - acc: 0.9964\n",
      "---------------------------Precision-----------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       266\n",
      "           1       0.93      0.93      0.93       291\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       557\n",
      "   macro avg       0.93      0.93      0.93       557\n",
      "weighted avg       0.93      0.93      0.93       557\n",
      " samples avg       0.93      0.93      0.93       557\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************Accuracy****************************\n",
      "The all of acc score:  [92.63913825127553]\n",
      "The average score: 92.64% (+/- 0.00%)\n",
      "---------------------------F1-Score-----------------------------\n",
      "The all of f1_scores score:  [0.9262544684231431]\n",
      "The average score: 0.93% (+/- 0.00%)\n",
      "+++++++++++++++++++++++++++Recall-Score+++++++++++++++++++++++++\n",
      "The all of f1_scores score:  [0.9263235408107899]\n",
      "The average score: 0.93% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:UTF-8 -*-\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D,Conv2D,AveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense,BatchNormalization,advanced_activations,initializers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from PIL import Image,ImageFile\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import f1_score,recall_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "# use GPU block\n",
    "# 随机数设置，便于产生相同的随机数\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 定义 K-fold 交叉验证 参数\n",
    "kfold= KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 128,128\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "flag=1\n",
    "n_classes=2\n",
    "flag=1\n",
    "f1_scores=[]\n",
    "recall_scores=[]\n",
    "cvscores=[]\n",
    "for train, test in kfold.split(x_train, y_train):\n",
    "    # Cross validation 交叉验证结果\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-6))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5,5), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-6))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5,5), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-6))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(BatchNormalization(epsilon=1e-6))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    # adam = Adam(lr=0.001, beta_1=0.79, beta_2=0.999, epsilon=1e-8) \n",
    "    # sgd =SGD(lr=0.01, decay=1e-6, momentum=0.89, nesterov=True)\n",
    "    model.compile(optimizer=\"sgd\", loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "    #model.summary()\n",
    "    model.fit(x_train[train], y_train[train], epochs=32, batch_size=20, verbose=1)\n",
    "    model.save(\"/home/aqts/yangHong/first-spam-experiment/h5_model/image_cnn_model_k_flod\"+str(flag)+\".h5\")\n",
    "    # 评估模型\n",
    "    # accuracy\n",
    "    scores = model.evaluate(x_train[test], y_train[test], verbose=0)\n",
    "#     print(\"%s: %s %.2f%%\" % (model.metrics_names[1], ':', scores[1]*100))\n",
    "    cvscores.append(scores[1]*100)\n",
    "    y_pred_score=y_pred=model.predict(x_train[test], 32)\n",
    "    #get precision\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i][0]>0.5):\n",
    "            y_pred[i][0]=1\n",
    "        else:\n",
    "            y_pred[i][0]=0\n",
    "        if(y_pred[i][1]>0.5):\n",
    "            y_pred[i][1]=1\n",
    "        else:\n",
    "            y_pred[i][1]=0\n",
    "    print(\"---------------------------Precision-----------------------------\")\n",
    "    print(classification_report(y_train[test],y_pred))\n",
    "    #f1-score\n",
    "    f1_scores.append(f1_score(y_train[test],y_pred,average = 'macro'))\n",
    "    #recall-score\n",
    "    recall_scores.append(recall_score(y_train[test],y_pred,average = 'macro'))\n",
    "    #get auc\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_train[test][:, i], y_pred_score[:, i])    \n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])   \n",
    "\n",
    "    # #Plot of a ROC curve for a specific class\n",
    "    plt.rcParams['figure.figsize']=(8,5)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[1], tpr[1], color='darkorange', label='ROC curve spam(auc = %0.4f)' % roc_auc[1])\n",
    "    plt.plot(fpr[0], tpr[0], color='green', label='ROC curve ham (auc = %0.4f)' % roc_auc[0])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC graph for predicting image dataset using the MMA-MF model')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(\"/home/aqts/yangHong/first-spam-experiment/experiment_result_roc/ROC_graph_for_Image\"+str(flag)+\".png\")\n",
    "    plt.show()\n",
    "    flag=flag+1\n",
    "\n",
    "print(\"***************************Accuracy****************************\")\n",
    "print(\"The all of acc score: \" ,(cvscores))\n",
    "print(\"The average score: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "print(\"---------------------------F1-Score-----------------------------\")\n",
    "print(\"The all of f1_scores score: \" ,(f1_scores))\n",
    "print(\"The average score: %.2f%% (+/- %.2f%%)\" % (np.mean(f1_scores), np.std(f1_scores)))\n",
    "print(\"+++++++++++++++++++++++++++Recall-Score+++++++++++++++++++++++++\")\n",
    "print(\"The all of f1_scores score: \" ,(recall_scores))\n",
    "print(\"The average score: %.2f%% (+/- %.2f%%)\" % (np.mean(recall_scores), np.std(recall_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************Accuracy****************************\n",
      "The all of acc score:  [92.63913825127553]\n",
      "The average score: 92.6391% (+/- 0.0000%)\n",
      "---------------------------F1-Score-----------------------------\n",
      "The all of f1_scores score:  [0.9262544684231431]\n",
      "The average score: 0.9263% (+/- 0.0000%)\n",
      "+++++++++++++++++++++++++++Recall-Score+++++++++++++++++++++++++\n",
      "The all of recall_scores score:  [0.9263235408107899]\n",
      "The average score: 0.9263% (+/- 0.0000%)\n"
     ]
    }
   ],
   "source": [
    "print(\"***************************Accuracy****************************\")\n",
    "print(\"The all of acc score: \" ,(cvscores))\n",
    "print(\"The average score: %.4f%% (+/- %.4f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "print(\"---------------------------F1-Score-----------------------------\")\n",
    "print(\"The all of f1_scores score: \" ,(f1_scores))\n",
    "print(\"The average score: %.4f%% (+/- %.4f%%)\" % (np.mean(f1_scores), np.std(f1_scores)))\n",
    "print(\"+++++++++++++++++++++++++++Recall-Score+++++++++++++++++++++++++\")\n",
    "print(\"The all of recall_scores score: \" ,(recall_scores))\n",
    "print(\"The average score: %.4f%% (+/- %.4f%%)\" % (np.mean(recall_scores), np.std(recall_scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
